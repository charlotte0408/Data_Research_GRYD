{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this note book (without risk factor)\n",
    "### Compute the Mean Squared Errors \n",
    "### Finally have the same data set with friends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import and Matrix Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in gender in R1 and R2 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Intersection_Y1R1R2_0702Y1_R1_R2_on_0702clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Intersection_Y1R1R2_0702Y1_0702.csv')\n",
    "Y1 = df.loc[:, 'UniqueID':'t39_combo']\n",
    "Y1['Gender'] = df['Gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>UniqueID</th>\n",
       "      <th>a1_combo</th>\n",
       "      <th>a2_combo</th>\n",
       "      <th>a3_combo</th>\n",
       "      <th>a4_combo</th>\n",
       "      <th>a5_combo</th>\n",
       "      <th>a6_combo</th>\n",
       "      <th>b7_combo</th>\n",
       "      <th>...</th>\n",
       "      <th>Age</th>\n",
       "      <th>Date</th>\n",
       "      <th>Gender</th>\n",
       "      <th>GRYD_Zone</th>\n",
       "      <th>Ethnicity_Asian</th>\n",
       "      <th>Ethnicity_Black</th>\n",
       "      <th>Ethnicity_Latino</th>\n",
       "      <th>Ethnicity_White</th>\n",
       "      <th>Ethnicity_Other</th>\n",
       "      <th>RiskFactor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>851</td>\n",
       "      <td>3538.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2009-11-12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>869</td>\n",
       "      <td>3552.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2009-11-16</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>892</td>\n",
       "      <td>3569.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2009-11-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>895</td>\n",
       "      <td>3570.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2009-11-18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>919</td>\n",
       "      <td>3586.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2009-11-19</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  UniqueID  a1_combo  a2_combo  a3_combo  a4_combo  \\\n",
       "0           0           851    3538.0       3.0       3.0       4.0       4.0   \n",
       "1           3           869    3552.0       3.0       4.0       4.0       3.0   \n",
       "2           6           892    3569.0       3.0       5.0       4.0       1.0   \n",
       "3           9           895    3570.0       3.0       4.0       2.0       3.0   \n",
       "4          12           919    3586.0       4.0       4.0       5.0       5.0   \n",
       "\n",
       "   a5_combo  a6_combo  b7_combo     ...       Age        Date  Gender  \\\n",
       "0       3.0       2.0       3.0     ...      13.0  2009-11-12     1.0   \n",
       "1       4.0       2.0       4.0     ...      14.0  2009-11-16     2.0   \n",
       "2       4.0       2.0       5.0     ...      13.0  2009-11-17     1.0   \n",
       "3       4.0       3.0       3.0     ...      10.0  2009-11-18     1.0   \n",
       "4       4.0       1.0       3.0     ...      11.0  2009-11-19     2.0   \n",
       "\n",
       "   GRYD_Zone  Ethnicity_Asian  Ethnicity_Black  Ethnicity_Latino  \\\n",
       "0        4.0              0.0              0.0               1.0   \n",
       "1        5.0              0.0              0.0               1.0   \n",
       "2       17.0              0.0              0.0               1.0   \n",
       "3       17.0              1.0              0.0               0.0   \n",
       "4        4.0              0.0              0.0               1.0   \n",
       "\n",
       "   Ethnicity_White  Ethnicity_Other  RiskFactor  \n",
       "0              0.0              0.0         7.0  \n",
       "1              0.0              0.0         7.0  \n",
       "2              0.0              0.0         7.0  \n",
       "3              0.0              0.0         5.0  \n",
       "4              0.0              0.0         7.0  \n",
       "\n",
       "[5 rows x 90 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Intersection_Y1R1R2_0702R1_0702.csv')\n",
    "R1 = df.loc[:, 'UniqueID':'t39_combo']\n",
    "R1['Gender'] = df['Gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Intersection_Y1R1R2_0702R2_0702.csv')\n",
    "R2 = df.loc[:, 'UniqueID':'t39_combo']\n",
    "R2['Gender'] = df['Gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change all nan gender values in R1 according to their values in Y1\n",
    "\n",
    "for index in R1.index:\n",
    "    gender = Y1.loc[index,'Gender']\n",
    "    R1.loc[index, 'Gender'] = gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change all nan gender values in R2 according to their values in Y1\n",
    "\n",
    "for index in R2.index:\n",
    "    gender = Y1.loc[index,'Gender']\n",
    "    R2.loc[index, 'Gender'] = gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop IDs with Nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#indices\n",
    "columns = Y1.columns.tolist()\n",
    "columns = columns[:-1]\n",
    "\n",
    "#create list of indices that have NaN values in their rows\n",
    "index_list=[]\n",
    "for col in columns:   \n",
    "    index_list.extend(Y1[Y1[col].isnull()].index.tolist())\n",
    "index_list\n",
    "\n",
    "#make this list unique\n",
    "my_set = set(index_list)\n",
    "unique_index_list = list(my_set)\n",
    "unique_index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[512, 770, 169, 624, 402, 56, 1087, 927]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create list of indices that have NaN values in their rows\n",
    "index_list=[]\n",
    "for col in columns:   \n",
    "    index_list.extend(R1[R1[col].isnull()].index.tolist())\n",
    "index_list\n",
    "\n",
    "#make this list unique\n",
    "my_set = set(index_list)\n",
    "unique_index_list1 = list(my_set)\n",
    "unique_index_list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1297, 182, 347, 446, 763]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create list of indices that have NaN values in their rows\n",
    "index_list=[]\n",
    "for col in columns:   \n",
    "    index_list.extend(R2[R2[col].isnull()].index.tolist())\n",
    "index_list\n",
    "\n",
    "#make this list unique\n",
    "my_set = set(index_list)\n",
    "unique_index_list2 = list(my_set)\n",
    "unique_index_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14334.0, 17710.0, 11189.0, 16486.0, 12668.0, 4960.0, 25920.0, 22418.0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make list of UniqueIDs associated with these NaN values\n",
    "ID_list = []\n",
    "for i in unique_index_list1:\n",
    "    ID_list.append(R1.loc[i,'UniqueID'])\n",
    "ID_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14334.0,\n",
       " 17710.0,\n",
       " 11189.0,\n",
       " 16486.0,\n",
       " 12668.0,\n",
       " 4960.0,\n",
       " 25920.0,\n",
       " 22418.0,\n",
       " 32402.0,\n",
       " 11205.0,\n",
       " 12560.0,\n",
       " 13876.0,\n",
       " 17696.0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make list of UniqueIDs associated with these NaN values\n",
    "for i in unique_index_list2:\n",
    "    ID_list.append(R2.loc[i,'UniqueID'])\n",
    "ID_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop these IDs from the data\n",
    "for id in ID_list:\n",
    "    Y1 = Y1[Y1['UniqueID']!=id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop these IDs from the data\n",
    "for id in ID_list:\n",
    "    R1 = R1[R1['UniqueID']!=id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop these IDs from the data\n",
    "for id in ID_list:\n",
    "    R2 = R2[R2['UniqueID']!=id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add gender control indicator in the input matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1['Gender1'] = 0\n",
    "Y1['Gender2'] = 0\n",
    "for i in Y1.index:\n",
    "    if Y1.loc[i,'Gender'] == 1:\n",
    "        Y1.set_value(i,'Gender1',1) \n",
    "        Y1.set_value(i,'Gender2',0) \n",
    "    else:\n",
    "        Y1.set_value(i,'Gender1',0) \n",
    "        Y1.set_value(i,'Gender2',1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "R1['Gender1'] = 0\n",
    "R1['Gender2'] = 0\n",
    "for i in R1.index:\n",
    "    if R1.loc[i,'Gender'] == 1:\n",
    "        R1.set_value(i,'Gender1',1) \n",
    "        R1.set_value(i,'Gender2',0) \n",
    "    else:\n",
    "        R1.set_value(i,'Gender1',0) \n",
    "        R1.set_value(i,'Gender2',1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2['Gender1'] = 0\n",
    "R2['Gender2'] = 0\n",
    "for i in R2.index:\n",
    "    if R2.loc[i,'Gender'] == 1:\n",
    "        R2.set_value(i,'Gender1',1) \n",
    "        R2.set_value(i,'Gender2',0) \n",
    "    else:\n",
    "        R2.set_value(i,'Gender1',0) \n",
    "        R2.set_value(i,'Gender2',1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UniqueID</th>\n",
       "      <th>a1_combo</th>\n",
       "      <th>a2_combo</th>\n",
       "      <th>a3_combo</th>\n",
       "      <th>a4_combo</th>\n",
       "      <th>a5_combo</th>\n",
       "      <th>a6_combo</th>\n",
       "      <th>b7_combo</th>\n",
       "      <th>b8_combo</th>\n",
       "      <th>b9_combo</th>\n",
       "      <th>...</th>\n",
       "      <th>h33_combo</th>\n",
       "      <th>h34_combo</th>\n",
       "      <th>h35_combo</th>\n",
       "      <th>h36_combo</th>\n",
       "      <th>h37_combo</th>\n",
       "      <th>t38_combo</th>\n",
       "      <th>t39_combo</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Gender1</th>\n",
       "      <th>Gender2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3538.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3552.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3569.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3570.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3586.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UniqueID  a1_combo  a2_combo  a3_combo  a4_combo  a5_combo  a6_combo  \\\n",
       "0    3538.0       2.0       4.0       2.0       1.0       2.0       1.0   \n",
       "1    3552.0       2.0       2.0       2.0       1.0       2.0       1.0   \n",
       "2    3569.0       4.0       4.0       3.0       1.0       1.0       2.0   \n",
       "3    3570.0       2.0       3.0       2.0       2.0       2.0       1.0   \n",
       "4    3586.0       4.0       4.0       4.0       1.0       4.0       1.0   \n",
       "\n",
       "   b7_combo  b8_combo  b9_combo   ...     h33_combo  h34_combo  h35_combo  \\\n",
       "0       2.0       2.0       2.0   ...           2.0        1.0        2.0   \n",
       "1       2.0       1.0       2.0   ...           2.0        1.0        1.0   \n",
       "2       4.0       4.0       4.0   ...           4.0        3.0        2.0   \n",
       "3       2.0       1.0       2.0   ...           1.0        1.0        1.0   \n",
       "4       3.0       4.0       4.0   ...           1.0        1.0        2.0   \n",
       "\n",
       "   h36_combo  h37_combo  t38_combo  t39_combo  Gender  Gender1  Gender2  \n",
       "0        2.0        1.0        0.0        0.0     1.0        1        0  \n",
       "1        3.0        1.0        0.0        0.0     2.0        0        1  \n",
       "2        4.0        2.0        0.0        1.0     1.0        1        0  \n",
       "3        1.0        1.0        0.0        0.0     1.0        1        0  \n",
       "4        2.0        4.0        0.0        0.0     2.0        0        1  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1 = Y1.drop('UniqueID',axis = 1)\n",
    "Y1 = Y1.drop('Gender',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 1663)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y1 = Y1.transpose()\n",
    "Y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "R1 = R1.drop('UniqueID',axis = 1)\n",
    "R1 = R1.drop('Gender',axis = 1)\n",
    "R1 = R1.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2 = R2.drop('UniqueID',axis = 1)\n",
    "R2 = R2.drop('Gender',axis = 1)\n",
    "R2 = R2.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize all responses to (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(Y1.shape[1]):\n",
    "    Y1.iloc[37,i]=Y1.iloc[37,i]+1\n",
    "    Y1.iloc[38,i]=Y1.iloc[38,i]+1\n",
    "    R1.iloc[37,i]=R1.iloc[37,i]+1\n",
    "    R1.iloc[38,i]=R1.iloc[38,i]+1\n",
    "    R2.iloc[37,i]=R2.iloc[37,i]+1\n",
    "    R2.iloc[38,i]=R2.iloc[38,i]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "newlist=[]\n",
    "for i in range(9):\n",
    "    newlist.append(i)\n",
    "for i in range(16,39):\n",
    "    newlist.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in newlist:\n",
    "    for j in range (Y1.shape[1]):\n",
    "        Y1.iloc[i,j]=(Y1.iloc[i,j]-1)/4\n",
    "        R1.iloc[i,j]=(R1.iloc[i,j]-1)/4\n",
    "        R2.iloc[i,j]=(R2.iloc[i,j]-1)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1 = Y1.values\n",
    "R1 = R1.values\n",
    "R2 = R2.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split test and train datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41, 1330)\n",
      "(41, 1330)\n",
      "(41, 333)\n",
      "(41, 333)\n"
     ]
    }
   ],
   "source": [
    "Index = list(range(Y1.shape[1]))\n",
    "random.shuffle(Index)\n",
    "Train_X = np.empty((Y1.shape[0],0))\n",
    "Test_X = np.empty((Y1.shape[0],0))\n",
    "Train_Y = np.empty((Y1.shape[0],0))\n",
    "Test_Y = np.empty((Y1.shape[0],0))\n",
    "for i in range(round(len(Index)*0.8)):\n",
    "    Train_X = np.hstack((Train_X,Y1[:,Index[i]].reshape(-1,1)))\n",
    "    #Train_X = np.hstack((Train_X,R1[:,Index[i]].reshape(-1,1)))\n",
    "    Train_Y = np.hstack((Train_Y,R1[:,Index[i]].reshape(-1,1)))\n",
    "    #Train_Y = np.hstack((Train_Y,R2[:,Index[i]].reshape(-1,1)))\n",
    "for i in range(round(len(Index)*0.8),len(Index)):\n",
    "    Test_X = np.hstack((Test_X,Y1[:,Index[i]].reshape(-1,1)))\n",
    "    #Test_X = np.hstack((Test_X,R1[:,Index[i]].reshape(-1,1)))\n",
    "    Test_Y = np.hstack((Test_Y,R1[:,Index[i]].reshape(-1,1)))\n",
    "    #Test_Y = np.hstack((Test_Y,R2[:,Index[i]].reshape(-1,1)))\n",
    "print(Train_X.shape)\n",
    "print(Train_Y.shape)\n",
    "print(Test_X.shape)\n",
    "print(Test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1_r = Train_X[0:39]\n",
    "Y1_f = Train_X[39:41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "R1_r = Train_Y[0:39]\n",
    "R1_f = Train_Y[39:41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_X_r = Test_X[0:39]\n",
    "Test_X_c = Test_X[39:41]\n",
    "Test_Y_r = Test_Y[0:39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2_r = R2[0:39]\n",
    "R2_f = R2[39:41]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DMDc for Gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y1 to R1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the dimension parameters for later code\n",
    "\n",
    "XwC = 41\n",
    "X = 39\n",
    "C = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVD for the Omega matrices(Combination of the original X-input matrix and control factors)\n",
    "\n",
    "U_Y1,Sig_Y1,V_Y1=np.linalg.svd(Train_X, full_matrices=False)    \n",
    "V_Y1_T=V_Y1.conjugate().transpose()\n",
    "Sig_inv_Y1=np.zeros((XwC, XwC))\n",
    "for i in range(XwC):\n",
    "    for j in range(XwC):\n",
    "        if i==j:\n",
    "            Sig_inv_Y1[i][j]=1/Sig_Y1[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting U matrixes to one include only information of responses and another one with control factors\n",
    "\n",
    "U_Y1_Q = U_Y1[:X,:]\n",
    "U_Y1_Q_T = U_Y1_Q.conjugate().transpose()\n",
    "U_Y1_G = U_Y1[X:XwC,:]\n",
    "U_Y1_G_T = U_Y1_G.conjugate().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVD for the X' matrix(the next time input matrix of only questions)\n",
    "\n",
    "U_R1_r,Sig_R1_r,V_R1_r=np.linalg.svd(R1_r, full_matrices=False)\n",
    "U_R1_r_T = U_R1_r.conjugate().transpose()\n",
    "V_R1_r_T=V_R1_r.conjugate().transpose()\n",
    "Sig_inv_R1_r=np.zeros((X, X))\n",
    "for i in range(X):\n",
    "    for j in range(X):\n",
    "        if i==j:\n",
    "            Sig_inv_R1_r[i][j]=1/Sig_R1_r[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 39)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_step2=np.dot(R1_r,V_Y1_T)\n",
    "A_step3=np.dot(A_step2,Sig_inv_Y1)\n",
    "A_Y1_R1=np.dot(A_step3,U_Y1_Q_T)\n",
    "A_Y1_R1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate the transformation B matrix\n",
    "\n",
    "B_Y1_R1=np.dot(A_step3,U_Y1_G_T)\n",
    "B_Y1_R1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.13412856,  0.12054367],\n",
       "       [ 0.26639715,  0.29657491],\n",
       "       [ 0.24771433,  0.25888278],\n",
       "       [-0.03975953, -0.04327864],\n",
       "       [ 0.06658763,  0.04141271],\n",
       "       [-0.00921774, -0.01843258],\n",
       "       [ 0.1526557 ,  0.11153709],\n",
       "       [ 0.12850089,  0.08282138],\n",
       "       [ 0.14942406,  0.10881763],\n",
       "       [ 0.41600501,  0.41230349],\n",
       "       [ 0.05345969,  0.0248122 ],\n",
       "       [ 0.1289833 ,  0.05935085],\n",
       "       [ 0.21504615,  0.20160981],\n",
       "       [ 0.20824007,  0.34960148],\n",
       "       [ 0.52655268,  0.59523948],\n",
       "       [ 0.15756143,  0.21187349],\n",
       "       [ 0.17595492,  0.15399471],\n",
       "       [ 0.12376108,  0.12167646],\n",
       "       [ 0.21987684,  0.21107501],\n",
       "       [ 0.26718297,  0.27729476],\n",
       "       [ 0.15519298,  0.14983649],\n",
       "       [ 0.28375977,  0.27027146],\n",
       "       [ 0.14227103,  0.10523386],\n",
       "       [ 0.15719806,  0.1407004 ],\n",
       "       [ 0.2000723 ,  0.17301258],\n",
       "       [ 0.31912098,  0.29249004],\n",
       "       [ 0.16108977,  0.1863125 ],\n",
       "       [ 0.06441617,  0.07522169],\n",
       "       [ 0.25294676,  0.24451501],\n",
       "       [ 0.26108007,  0.2592539 ],\n",
       "       [ 0.05804649,  0.06852948],\n",
       "       [ 0.18758965,  0.21791046],\n",
       "       [ 0.0628168 ,  0.03826502],\n",
       "       [ 0.02781088,  0.02367785],\n",
       "       [ 0.09248963,  0.09952202],\n",
       "       [ 0.18332369,  0.22327629],\n",
       "       [ 0.10571397,  0.11026612],\n",
       "       [ 0.07745222,  0.0856714 ],\n",
       "       [-0.00637015,  0.00481198]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_Y1_R1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_Y1, vectors_Y1 = np.linalg.eig(A_Y1_R1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.55682823+0.05066247j,  0.55682823-0.05066247j,\n",
       "        0.46641191+0.j        ,  0.36340175+0.05818991j,\n",
       "        0.36340175-0.05818991j,  0.04505698+0.12410133j,\n",
       "        0.04505698-0.12410133j, -0.00906084+0.j        ,\n",
       "       -0.00354009+0.02197803j, -0.00354009-0.02197803j,\n",
       "        0.19809415+0.15446519j,  0.19809415-0.15446519j,\n",
       "        0.05194501+0.09761161j,  0.05194501-0.09761161j,\n",
       "        0.282653  +0.11737336j,  0.282653  -0.11737336j,\n",
       "        0.35603761+0.j        ,  0.16760691+0.12455067j,\n",
       "        0.16760691-0.12455067j,  0.31821265+0.j        ,\n",
       "        0.28977761+0.05750795j,  0.28977761-0.05750795j,\n",
       "        0.11059277+0.1024255j ,  0.11059277-0.1024255j ,\n",
       "        0.08869227+0.07475297j,  0.08869227-0.07475297j,\n",
       "        0.2717331 +0.j        ,  0.20382408+0.06675895j,\n",
       "        0.20382408-0.06675895j,  0.22601218+0.03543798j,\n",
       "        0.22601218-0.03543798j,  0.06280543+0.j        ,\n",
       "        0.0718846 +0.j        ,  0.10386578+0.00960913j,\n",
       "        0.10386578-0.00960913j,  0.21776067+0.j        ,\n",
       "        0.1332506 +0.j        ,  0.16210541+0.02037483j,\n",
       "        0.16210541-0.02037483j])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_Y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "eiglog_Y1 = np.log(values_Y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamphi_Y1=np.zeros(39)\n",
    "for i in range (39):\n",
    "    rep=vectors_Y1[i]\n",
    "    norm=np.linalg.norm(rep)\n",
    "    val=np.absolute(values_Y1[i])*norm\n",
    "    lamphi_Y1[i]=val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute MSE between predictions and actual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y1 to R1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_A = np.dot(A_Y1_R1,Test_X_r)\n",
    "predictions_B = np.dot(B_Y1_R1,Test_X_c)\n",
    "predictions = predictions_A + predictions_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(predictions)\n",
    "df.to_csv('predictions_Y1_R1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09930891420666887"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = mean_squared_error(Test_Y_r, predictions)\n",
    "mse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
