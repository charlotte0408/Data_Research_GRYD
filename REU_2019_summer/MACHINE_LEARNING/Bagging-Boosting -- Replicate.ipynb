{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from itertools import combinations\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC,NuSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import sys\n",
    "#import tensorflow as tf\n",
    "#from ELM.elm import ELM\n",
    "import os\n",
    "import argparse\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the data is eligible\n",
    "def If_Elig(data):\n",
    "    return (data>=5).astype(int)\n",
    "\n",
    "# Find the position of the data\n",
    "def find_pos(data,value, order):\n",
    "    max_num = np.count_nonzero(data[:,0]==value)\n",
    "    if order > max_num:\n",
    "        return -1\n",
    "    else:\n",
    "        return np.nonzero(data[:,0]==value)[0][order-1]\n",
    "\n",
    "# Model Prediction\n",
    "def model_predict(model,x):\n",
    "    return model.predict(x)\n",
    "\n",
    "# Hand Written Soft Voting\n",
    "def Vote(Classifier,Prediction,Score):\n",
    "    leng = len(Classifier)\n",
    "    sum_score = sum(Score)\n",
    "    Weighted = 0\n",
    "    for i in range(leng):\n",
    "        Weighted += Prediction[i]*Score[i]/sum_score\n",
    "    return Weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following def are packages training, which can be searched on sklearn\n",
    "\n",
    "def KNN(n,x,y):\n",
    "    knn = KNeighborsClassifier(n_neighbors=n, n_jobs=-1)\n",
    "    knn.fit(x,y)\n",
    "    return knn\n",
    "\n",
    "\n",
    "def SVM(x,y):\n",
    "    svc = SVC()\n",
    "    svc.fit(x,y)\n",
    "    return svc\n",
    "\n",
    "\n",
    "def NuSVM(x,y):\n",
    "    nus = [_ / 10 for _ in range(1, 11, 1)]\n",
    "    for nu in nus:\n",
    "        nusvc = NuSVC(nu=nu)\n",
    "        try:\n",
    "            nusvc.fit(x,y)\n",
    "            return nusvc\n",
    "        except ValueError as e:\n",
    "            print(\"nu {} not feasible\".format(nu))\n",
    "\n",
    "def Bayesian(x,y):\n",
    "    bayesian = GaussianNB()\n",
    "    bayesian.fit(x,y)\n",
    "    return bayesian\n",
    "\n",
    "\n",
    "def DecisionTree(x,y,criterion='gini',max_depth=None, min_samples_split=2, min_samples_leaf=1, max_features=None):\n",
    "    Tree = DecisionTreeClassifier(criterion=criterion,max_depth=max_depth,min_samples_split= \\\n",
    "                                               min_samples_split,min_samples_leaf=min_samples_leaf,\n",
    "                                               max_features=max_features)\n",
    "    Tree.fit(x,y)\n",
    "    return Tree\n",
    "\n",
    "\n",
    "def RandomForest(x,y,n_estimator=10,criterion='gini'):\n",
    "    Forest = RandomForestClassifier(n_estimators=n_estimator,criterion=criterion)\n",
    "    Forest.fit(x,y)\n",
    "    return Forest\n",
    "\n",
    "\n",
    "def LinearC(x,y):\n",
    "    linear = SGDClassifier()\n",
    "    linear.fit(x,y)\n",
    "    return linear\n",
    "\n",
    "\n",
    "def MLP(x,y,hidden_layer_size=(100,),activation='relu',solver='adam',learning_rate_init=0.01, learning_rate='adaptive'):\n",
    "    if solver=='adam':\n",
    "        MLP = MLPClassifier(hidden_layer_sizes=hidden_layer_size, activation=activation, solver= \\\n",
    "                                               solver, learning_rate_init=learning_rate_init, learning_rate=learning_rate)\n",
    "    elif solver=='sgd':\n",
    "        MLP = MLPClassifier(hidden_layer_sizes=hidden_layer_size, activation=activation, solver= \\\n",
    "            solver, learning_rate_init=learning_rate_init)\n",
    "    else:\n",
    "        MLP = MLPClassifier(hidden_layer_sizes=hidden_layer_size, activation=activation, solver= \\\n",
    "            solver)\n",
    "    MLP.fit(x,y)\n",
    "    return MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Data\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "cleaned_filepath = 'Questions_ReconstructedFactor.csv'\n",
    "df = pd.read_csv(cleaned_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr = df.loc[:, 'UniqueID':'ij56_ever_combo']\n",
    "dft = df.loc[:,\"ReconstructedFactor\"]\n",
    "d = dfr.convert_objects(convert_numeric=True)\n",
    "dt = dft.convert_objects(convert_numeric=True)\n",
    "xr = d.values\n",
    "y = dt.values\n",
    "x = xr[~np.isnan(xr).any(axis=1)]\n",
    "y = y[~np.isnan(xr).any(axis=1)]\n",
    "x_revise = np.empty((0,40))\n",
    "y_revise = np.empty((0,))\n",
    "\n",
    "for i in range(x.shape[0]):\n",
    "    if i == 0 and x[i,0] == x[i+1,0]:\n",
    "        x_revise = np.vstack([x_revise,[x[i,0:40]]])\n",
    "        y_revise = np.append(y_revise,y[i])\n",
    "    elif i == x.shape[0]-1 and x[i,0] == x[i-1,0]:\n",
    "        x_revise = np.vstack([x_revise,[x[i,0:40]]])\n",
    "        y_revise = np.append(y_revise,y[i])\n",
    "    elif i == x.shape[0]-1:\n",
    "        continue\n",
    "    elif x[i,0]==x[i+1,0] or x[i,0]==x[i-1,0]:\n",
    "        x_revise = np.vstack([x_revise,[x[i,0:40]]])\n",
    "        y_revise = np.append(y_revise,y[i])\n",
    "new_x = np.zeros((x_revise.shape[0],9))\n",
    "for i in range(x_revise.shape[0]):\n",
    "    new_x[i,0] = x_revise[i,0]\n",
    "    new_x[i,1] = np.sum(x_revise[i,1:7])\n",
    "    new_x[i,2] = np.sum(x_revise[i,7:10])\n",
    "    new_x[i,3] = np.sum(x_revise[i,10:17])\n",
    "    new_x[i,4] = np.sum(x_revise[i,17:21])\n",
    "    new_x[i,5] = np.sum(x_revise[i,21:27])\n",
    "    new_x[i,6] = np.sum(x_revise[i,27:32])\n",
    "    new_x[i,7] = np.sum(x_revise[i,32:38])\n",
    "    new_x[i,8] = np.sum(x_revise[i,38:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(xr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1042.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17779"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_revise.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With scale score\n",
    "\n",
    "real_x = np.empty((0,new_x.shape[1]-1))\n",
    "real_y = np.empty((0,))\n",
    "for j in range(1,4):\n",
    "    for i in range(1000,int(max(new_x[:,0]))):\n",
    "        pos1 = find_pos(new_x,i,j)\n",
    "        pos2 = find_pos(new_x,i,j+1)\n",
    "        if pos1 != -1 and pos2 != -1:\n",
    "            real_x = np.vstack([real_x,[new_x[pos1,1:]]])\n",
    "            real_y = np.append(real_y,y_revise[pos2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2. 3. 4. 5. 6. 7. 8.] [3044 1931 1221  996  893  845  604  361  192]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(real_y, return_counts=True)\n",
    "print(unique,counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance the dataset\n",
    "for i in range(10):\n",
    "    print(\"Number of Instance %d is %d\" % (i,np.count_nonzero(real_y==i)))\n",
    "zero = 0\n",
    "for i in range(real_y.shape[0]):\n",
    "    if real_y[i] == 0 and zero<1000:\n",
    "        real_x = np.vstack([real_x,[real_x[i,:]]])\n",
    "        real_y = np.append(real_y,real_y[i])\n",
    "        zero += 1\n",
    "    if real_y[i] == 1:\n",
    "        real_x = np.vstack([real_x,[real_x[i,:]]])\n",
    "        real_y = np.append(real_y,real_y[i])\n",
    "    elif real_y[i] == 2:\n",
    "        for _ in range(2):\n",
    "            real_x = np.vstack([real_x,[real_x[i,:]]])\n",
    "            real_y = np.append(real_y,real_y[i])\n",
    "    elif real_y[i] == 3:\n",
    "        for _ in range(2):\n",
    "            real_x = np.vstack([real_x,[real_x[i,:]]])\n",
    "            real_y = np.append(real_y,real_y[i])\n",
    "    elif real_y[i] == 4 or real_y[i] == 5:\n",
    "        for _ in range(3):\n",
    "            real_x = np.vstack([real_x,[real_x[i,:]]])\n",
    "            real_y = np.append(real_y,real_y[i])\n",
    "    elif real_y[i] == 6:\n",
    "        for _ in range(4):\n",
    "            real_x = np.vstack([real_x,[real_x[i,:]]])\n",
    "            real_y = np.append(real_y,real_y[i])\n",
    "    elif real_y[i] == 7:\n",
    "        for _ in range(8):\n",
    "            real_x = np.vstack([real_x,[real_x[i,:]]])\n",
    "            real_y = np.append(real_y,real_y[i])\n",
    "    elif real_y[i] == 8:\n",
    "        for _ in range(16):\n",
    "            real_x = np.vstack([real_x,[real_x[i,:]]])\n",
    "            real_y = np.append(real_y,real_y[i])\n",
    "for i in range(10):\n",
    "    print(\"Number of Instance %d is %d\" % (i,np.count_nonzero(real_y==i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter\n"
     ]
    }
   ],
   "source": [
    "# After pressing Enter, the training starts\n",
    "wait = input('Enter')\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "x_train,x_test,y_train,y_test = train_test_split(real_x,real_y,test_size=0.2)\n",
    "model1 = RandomForestClassifier()\n",
    "model1.fit(x_train,y_train)\n",
    "model2 = RandomForestClassifier(criterion='entropy')\n",
    "model2.fit(x_train,y_train)\n",
    "model3 = RandomForestClassifier(bootstrap=False)\n",
    "model3.fit(x_train,y_train)\n",
    "bag = VotingClassifier(estimators=[('RF1',model1),('RF2',model2),('RF3',model3)],voting='soft')\n",
    "boost = AdaBoostClassifier(base_estimator=model1,n_estimators=5)\n",
    "bag.fit(x_train,y_train)\n",
    "boost.fit(x_train,y_train)\n",
    "y_pred1 = model1.predict(x_test)\n",
    "y_pred2 = bag.predict(x_test)\n",
    "y_pred3 = boost.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.71      0.90      0.79       662\n",
      "        1.0       0.83      0.85      0.84       752\n",
      "        2.0       0.96      0.91      0.93       795\n",
      "        3.0       0.97      0.90      0.93       635\n",
      "        4.0       0.99      0.94      0.97       760\n",
      "        5.0       0.99      0.94      0.97       685\n",
      "        6.0       1.00      0.96      0.98       595\n",
      "        7.0       1.00      0.98      0.99       579\n",
      "        8.0       1.00      1.00      1.00       674\n",
      "\n",
      "avg / total       0.94      0.93      0.93      6137\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.70      0.88      0.78       675\n",
      "        1.0       0.83      0.84      0.84       760\n",
      "        2.0       0.95      0.92      0.93       784\n",
      "        3.0       0.98      0.92      0.95       620\n",
      "        4.0       0.99      0.93      0.96       767\n",
      "        5.0       0.99      0.94      0.97       685\n",
      "        6.0       1.00      0.95      0.98       598\n",
      "        7.0       1.00      0.99      1.00       570\n",
      "        8.0       1.00      0.99      1.00       678\n",
      "\n",
      "avg / total       0.94      0.93      0.93      6137\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.82      0.86      0.84       803\n",
      "        1.0       0.84      0.87      0.85       740\n",
      "        2.0       0.95      0.94      0.95       767\n",
      "        3.0       0.97      0.95      0.96       601\n",
      "        4.0       0.99      0.97      0.98       733\n",
      "        5.0       0.99      0.97      0.98       667\n",
      "        6.0       1.00      0.98      0.99       583\n",
      "        7.0       1.00      0.99      1.00       569\n",
      "        8.0       1.00      1.00      1.00       674\n",
      "\n",
      "avg / total       0.95      0.94      0.94      6137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "print(classification_report(y_pred1,y_test))\n",
    "print(classification_report(y_pred2,y_test))\n",
    "print(classification_report(y_pred3,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4. 7. 5. 7. 5. 4. 6. 1. 0. 6. 0. 0. 1. 7. 3. 5. 1. 5. 7. 0. 5. 0. 2. 8.\n",
      " 8. 2. 5. 3. 7. 7. 6. 7. 2. 5. 0. 3. 8. 8. 7. 8. 8. 3. 2. 2. 0. 4. 5. 2.\n",
      " 6. 3.]\n",
      "[4. 7. 5. 7. 5. 4. 6. 1. 0. 6. 0. 0. 1. 7. 3. 5. 1. 5. 7. 0. 0. 1. 2. 8.\n",
      " 8. 2. 5. 3. 7. 7. 6. 7. 2. 5. 0. 3. 8. 8. 7. 8. 8. 3. 2. 2. 0. 4. 5. 2.\n",
      " 6. 3.]\n",
      "Total Time Used: 9.4462\n"
     ]
    }
   ],
   "source": [
    "# Demo for the first 50 data\n",
    "print(y_pred3[0:50])\n",
    "print(y_test[0:50])\n",
    "print(\"Total Time Used: %.4f\" % float(time.time()-start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
